const axios = require('axios');
const cheerio = require('cheerio');
const url = require('url');

const visitedUrls = new Set();
const baseUrl = 'https://example.com';

async function scrapeWebsite(link) {
    if (visitedUrls.has(link)) return;
    visitedUrls.add(link);

    try {
        const { data } = await axios.get(link);
        const $ = cheerio.load(data);

        // Extract and log text content
        const content = $('body').text().trim();
        console.log(`Content of ${link}:`);
        console.log(content);

        // Extract links and recursively scrape them
        $('a[href]').each((_, elem) => {
            const href = $(elem).attr('href');
            if (href && href.startsWith('/')) {
                const absoluteUrl = url.resolve(baseUrl, href);
                if (!visitedUrls.has(absoluteUrl)) {
                    scrapeWebsite(absoluteUrl);
                }
            } else if (href && href.startsWith(baseUrl)) {
                scrapeWebsite(href);
            }
        });
    } catch (err) {
        console.error(`Failed to scrape ${link}:`, err.message);
    }
}

scrapeWebsite(baseUrl);
